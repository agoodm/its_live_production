{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7123f4df-fbc5-4d11-ac57-15b19280deb5",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1><center>\n",
    "        <img src=\"https://its-live-data.s3.amazonaws.com/documentation/ITS_LIVE_logo.png\" width=\"500\"/>\n",
    "        </center></h1>\n",
    "    <h1><center>\n",
    "        glacier velocity point data access<br>\n",
    "        using Sentinel-2 basemap<br>\n",
    "        </center></h1>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Author: Mark Fahnestock, Geophysical Institute, University of Alaska Fairbanks\n",
    "Date: October 28, 2021\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c903c8c-0f30-4d5d-ae94-760fc55351b1",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook allows you to select a locaiton from high-resolution imagery, fetch all available ITS_LIVE glacier velocities for that location, and plot the results. These steps can be repeated to plot multiple locations on a single figure. \n",
    "\n",
    "Underling data is stored on AWS S3 as Zarr datacubes and is accessed without an intermediate server. Glacier velocities are derived from all available Landsat 8, Sentinel-1A/B, Sentinel-2A/B imagery.\n",
    "\n",
    "Please refer to the <a href=\"https://its-live.jpl.nasa.gov/\">project website</a> for further product infomation and for appraopriate data citation.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16515a84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up a local environment\n",
    "\n",
    "at the terminal:\n",
    ">conda create --name pg5 -c conda-forge h5netcdf fiona imagemagick shapely jupyter netcdf4 psutil h5py zarr matplotlib gdal  xarray  boto3 pyproj ipympl s3fs\n",
    "\n",
    "activate newly created environment:\n",
    "> conda activate pg5\n",
    "\n",
    "start jupyter in browser\n",
    "> jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first bunch of imports to read and plot timeseries from datacubes in S3 using xarry->zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "# import s3fs as s3\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.widgets import RectangleSelector\n",
    "import time\n",
    "\n",
    "#second bunch to identify datacubes from geojson catalog and picked point\n",
    "import json\n",
    "import shapely\n",
    "import fiona\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "# gdal for geospatial image io\n",
    "# recent conda installs have gdal in osgeo - just import gdal if this fails (could catch this if a problem)\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "# set variable\n",
    "global s3path2cube_previous\n",
    "s3path2cube_previous = None\n",
    "\n",
    "# use widget interface in this notebook for interactive pyplot plots\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as wdg\n",
    "# use ipywidgets for output text to track progress of download call\n",
    "# output widget is created here, but not displayed until the interactive plot code cell so it stays with plots\n",
    "outwdgt = wdg.Output(layout={'border': '1px solid blue'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set gdal (and via ogr -> fiona(s3://...)) to access public bucket anonomously\n",
    "gdal.SetConfigOption('AWS_NO_SIGN_REQUEST', 'YES')\n",
    "\n",
    "# mz_gd = gdal.Open(\n",
    "#             '/Volumes/Data/ITSLIVE_mark_mosaics/Alaska_S2_10m_2018/basemap_Alaska_S2_2018_10m_overview_100m.vrt'\n",
    "#             )\n",
    "mz_gd = gdal.Open(\n",
    "            '/vsicurl/https://glacierflow.nyc3.digitaloceanspaces.com/mosaics/ALA/basemap_Alaska_S2_2018_10m_overview_100m.vrt'\n",
    "            )\n",
    "\n",
    "\n",
    "mz_srs = mz_gd.GetSpatialRef()\n",
    "print(f\"EPSG:{mz_srs.GetAuthorityCode('PROJCS')}\")\n",
    "map_epsg = mz_srs.GetAuthorityCode('PROJCS')\n",
    "mz_gt = mz_gd.GetGeoTransform()\n",
    "mz_npix_x = mz_gd.RasterXSize\n",
    "mz_npix_y = mz_gd.RasterYSize\n",
    "print(f'image size ({mz_npix_x},{mz_npix_y}) meters per pixel ({mz_gt[1]},{mz_gt[5]})')\n",
    "\n",
    "dst = gdal.Translate('/vsimem/mem_img.tif',mz_gd,options='-tr 500 500 -r average')\n",
    "a = dst.ReadAsArray()\n",
    "b = np.moveaxis(a, 0, -1)\n",
    "\n",
    "#get extents of basemap\n",
    "gt = dst.GetGeoTransform()\n",
    "inmap_min_x = gt[0]\n",
    "inmap_max_x = gt[0] + dst.RasterXSize * gt[1]\n",
    "inmap_min_y = gt[3] + gt[5]*dst.RasterYSize\n",
    "inmap_max_y = gt[3]\n",
    "\n",
    "def get_detail_image(mz_gd,ileft,iright,ibottom,itop):\n",
    "    detaildst = gdal.Translate('/vsimem/mem_img.tif',mz_gd,options=f'-projwin {ileft} {itop} {iright} {ibottom}')\n",
    "    a = detaildst.ReadAsArray()\n",
    "    b = np.moveaxis(a, 0, -1)\n",
    "\n",
    "    #get extents of basemap\n",
    "    gt = detaildst.GetGeoTransform()\n",
    "    detailmap_min_x = gt[0]\n",
    "    detailmap_max_x = gt[0] + detaildst.RasterXSize * gt[1]\n",
    "    detailmap_min_y = gt[3] + gt[5]*detaildst.RasterYSize\n",
    "    detailmap_max_y = gt[3]\n",
    "    \n",
    "    return((b,(detailmap_min_x,detailmap_max_x,detailmap_min_y,detailmap_max_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44abc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class s3path2cubeException(Exception):\n",
    "    pass\n",
    "\n",
    "def get_s3path2cube(inpointxy,point_epsg_str):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    if point_epsg_str != '4326':\n",
    "        # point not in lon,lat, set up tranformation and convert it to lon,lat (epsg:4326)\n",
    "        inPROJtoLL = pyproj.Transformer.from_proj(f'epsg:{point_epsg_str}','epsg:4326',always_xy=True)\n",
    "        pointll = inPROJtoLL.transform(*inpointxy)\n",
    "    else:\n",
    "        # point already lon,lat\n",
    "        pointll = inpointxy\n",
    "    \n",
    "    # create Shapely point object for inclusion test\n",
    "    point = geometry.Point(*pointll) # point.coords.xy\n",
    "    \n",
    "    # find datacube outline that contains this point in geojson index file\n",
    "    cubef = None\n",
    "    \n",
    "#     s3/its-live-data.jpl.nasa.gov/datacubes/v01/datacubes_100km_v01.json\n",
    "        \n",
    "    with fiona.open('s3://its-live-data/test_datacubes/v02/datacubes_catalog.json','r') as infio:\n",
    "#     with fiona.open('s3://its-live-data.jpl.nasa.gov/datacubes/v01/datacubes_100km_v01.json','r') as infio:\n",
    "        for f in infio:\n",
    "            polygeom = geometry.shape(f['geometry'])\n",
    "            if polygeom.contains(point):\n",
    "                cubef = f\n",
    "                \n",
    "    if cubef:\n",
    "        print(f'found datacube - elapsed time: {(time.time()-start):10.2f}',flush=True)\n",
    "        \n",
    "        if point_epsg_str == cubef['properties']['data_epsg']:\n",
    "            point_cube_cr = inpointxy\n",
    "        else:\n",
    "            inPROJtoTilePROJ = pyproj.Transformer.from_proj(f'epsg:{point_epsg_str}',cubef['properties']['data_epsg'],always_xy=True)\n",
    "            point_cube_cr = inPROJtoTilePROJ.transform(*inpointxy)\n",
    "\n",
    "        # now test if point is in xy box for cube (should be most of time, could fail because of boundary curvature - 4326 box defined by lon,lat corners, but point chosen in basemap projection)                        \n",
    "        point_cube_cr_shapely = geometry.Point(*point_cube_cr)\n",
    "        polygeomxy = geometry.shape(cubef['properties']['geometry_epsg'])\n",
    "        if not polygeomxy.contains(point_cube_cr_shapely):\n",
    "            raise timeseriesException(f\"point is in lat,lon box but not {cubef['properties']['data_epsg']} box!!!!!!!\")\n",
    "            \n",
    "        # for zarr store modify URL for use in boto open - change http: to s3: and lose s3.amazonaws.com\n",
    "        s3path2cube = cubef['properties']['zarr_url'].replace('http:','s3:').replace('.s3.amazonaws.com','')\n",
    "        \n",
    "        return (s3path2cube, point_cube_cr)\n",
    "    else:\n",
    "        raise url2cubeException(f'no datacube found for point {pointll}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7aea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorator captures function output in widget\n",
    "@outwdgt.capture(clear_output=True,wait=True)\n",
    "def plotfig(pointxy,nax,map_epsg):\n",
    "    global ins3xr\n",
    "    global point_v \n",
    "    global s3path2cube_previous # hopefully these are available in the global context after a call...\n",
    "    \n",
    "    # pointxy is [x,y] coordinate in mapfig projection (map_epsg below), nax is plot axis for time series plot\n",
    "    start = time.time()\n",
    "    print(f'finding timeseries for point x={pointxy[0]:10.2f} y={pointxy[1]:10.2f} color {colors[color_index]} symbol {symbols[color_index]}',flush=True)\n",
    "\n",
    "    s3path2cube, point_cube_cr = get_s3path2cube(pointxy,map_epsg)\n",
    "    \n",
    "    # only map cube if it's differnet from the last - this could be updated to retain mappings for all unique cubes to avoid multiple reads\n",
    "    if s3path2cube != s3path2cube_previous:\n",
    "        ins3xr = xr.open_dataset(s3path2cube, engine=\"zarr\", storage_options={'anon':True})\n",
    "        s3path2cube_previous = s3path2cube\n",
    "    else:\n",
    "        print(f'data cube previously mapped')\n",
    "    \n",
    "    point_v = ins3xr[\"v\"].sel(x=point_cube_cr[0],y=point_cube_cr[1],method=\"nearest\")\n",
    "    point_v.load()\n",
    "  \n",
    "    dt = ins3xr['date_dt'].values \n",
    "    dt = dt.astype(float)*1.15741e-14;\n",
    "    max_dt = 90; # set the maximum image-pair time seperation (dt) that will be plotted\n",
    "    \n",
    "    nax.plot(ins3xr.mid_date[dt < max_dt],point_v[dt < max_dt], colors[color_index] + symbols[color_index])\n",
    "    total_time = time.time()-start\n",
    "\n",
    "    print(f'elapsed time: {total_time:10.2f} - {len(point_v)/total_time:6.1f} points per second',flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64daecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decorator captures function output in widget\n",
    "# @outwdgt.capture(clear_output=True,wait=True)\n",
    "# def plotfig(pointxy,nax):\n",
    "#     global ins3xr,point_v # hopefully these are available in the global context after a call...\n",
    "#     # pointxy is [x,y] coordinate in mapfig projection (map_epsg below), nax is plot axis for time series plot\n",
    "#     start = time.time()\n",
    "#     print(f'finding timeseries for point x={pointxy[0]:10.2f} y={pointxy[1]:10.2f} color {colors[color_index]} symbol {symbols[color_index]}',flush=True)\n",
    "# #     map_epsg = '3413'\n",
    "#     ins3xr,point_v = get_timeseries(pointxy,map_epsg) # returns xarray dataset object (used for time axis in plot) and already loaded v time series\n",
    "\n",
    "\n",
    "#     nax.plot(ins3xr.mid_date,point_v, colors[color_index] + symbols[color_index])\n",
    "#     total_time = time.time()-start\n",
    "#     print(f'elapsed time: {total_time:10.2f} - {len(point_v)/total_time:6.1f} points per second',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from first answer here (how to avoid recording clicks from fig zoom - only a click if no drag) \n",
    "# https://stackoverflow.com/questions/48446351/distinguish-button-press-event-from-drag-and-zoom-clicks-in-matplotlib\n",
    "class Click():\n",
    "    def __init__(self, ax, func, button=1):\n",
    "        self.ax=ax\n",
    "        self.func=func\n",
    "        self.button=button\n",
    "        self.press=False\n",
    "        self.move = False\n",
    "        self.c1=self.ax.figure.canvas.mpl_connect('button_press_event', self.onpress)\n",
    "        self.c2=self.ax.figure.canvas.mpl_connect('button_release_event', self.onrelease)\n",
    "        self.c3=self.ax.figure.canvas.mpl_connect('motion_notify_event', self.onmove)\n",
    "\n",
    "    def onclick(self,event):\n",
    "        if event.inaxes == self.ax:\n",
    "            if event.button == self.button:\n",
    "                self.func(event, self.ax)\n",
    "    def onpress(self,event):\n",
    "        self.press=True\n",
    "    def onmove(self,event):\n",
    "        if self.press:\n",
    "            self.move=True\n",
    "    def onrelease(self,event):\n",
    "        if self.press and not self.move:\n",
    "            self.onclick(event)\n",
    "        self.press=False; self.move=False\n",
    "        \n",
    "        \n",
    "pointxy = [np.nan, np.nan] # define here just to see if it is really set in the callback\n",
    "\n",
    "# set up color/symbol sequence for plots - will fail after 18 points...\n",
    "colors = 3*\"bgrcmk\"\n",
    "symbols =  \"++++++xxxxxxvvvvvv\"\n",
    "color_index = -1\n",
    "\n",
    "\n",
    "# Define a callback function that will update the map plot and call plotfig to read point data and plot it\n",
    "def onclick(event, ax):\n",
    "    global pointxy    # ensures the pointxy from the scope above is assigned the value when changed\n",
    "    global color_index\n",
    "    global map_epsg\n",
    "    \n",
    "    ptx = event.xdata\n",
    "    pty = event.ydata\n",
    "\n",
    "    color_index += 1\n",
    "    \n",
    "    # keep map axis from rescaling on point plot\n",
    "    ax.autoscale(False)\n",
    "    # plot marker on map at clicked location\n",
    "    ax.plot(ptx,pty, colors[color_index] + symbols[color_index], mew=4, ms=10)\n",
    "    \n",
    "    pointxy = [ptx,pty]\n",
    "    \n",
    "    # get time series at point and add it to the time series plot\n",
    "    plotfig(pointxy,plotax,map_epsg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90305ccd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from matplotlib.widgets import RectangleSelector\n",
    "# (from https://matplotlib.org/2.0.2/examples/widgets/rectangle_selector.html)\n",
    "\n",
    "mapfig,mapax = plt.subplots(1,1,figsize=(9,6))\n",
    "# plt.ion()\n",
    "# plt.show()\n",
    "mapfig.tight_layout()\n",
    "mapax.imshow(b,extent=[inmap_min_x,inmap_max_x,inmap_min_y,inmap_max_y])\n",
    "\n",
    "detailfig,detailax = plt.subplots(1,1,figsize=(9,6))\n",
    "# plt.ion()\n",
    "# plt.show()\n",
    "detailfig.tight_layout()\n",
    "# detailax.imshow(b,extent=[inmap_min_x,inmap_max_x,inmap_min_y,inmap_max_y])\n",
    "\n",
    "click = Click(detailax, onclick, button=1)\n",
    "\n",
    "# from IPython.display import display\n",
    "display(outwdgt)\n",
    "\n",
    "pltfig,plotax = plt.subplots(1,1,figsize=(9,6))\n",
    "plotax.set_xlabel('date')\n",
    "plotax.set_ylabel('speed (m/yr)')\n",
    "plotax.set_title('ice flow speed pulled directly from S3')\n",
    "\n",
    "pltfig.tight_layout()\n",
    "\n",
    "\n",
    "# decorator captures function output in widget\n",
    "@outwdgt.capture(clear_output=True,wait=True)\n",
    "def line_select_callback(eclick, erelease):\n",
    "    'eclick and erelease are the press and release events'\n",
    "    x1, y1 = eclick.xdata, eclick.ydata\n",
    "    x2, y2 = erelease.xdata, erelease.ydata\n",
    "    print(\"(%3.2f, %3.2f) --> (%3.2f, %3.2f)\" % (x1, y1, x2, y2))\n",
    "    print(\" The button you used were: %s %s\" % (eclick.button, erelease.button))\n",
    "\n",
    "    print(' Getting full res version.')\n",
    "    ileft,iright,ibottom,itop = np.round(np.array(toggle_selector.RS.extents)/10.)*10.\n",
    "    detailimg,(detail_min_x,detail_max_x,detail_min_y,detail_max_y) = get_detail_image(mz_gd,ileft,iright,ibottom,itop)\n",
    "    detailax.imshow(detailimg,extent=[detail_min_x,detail_max_x,detail_min_y,detail_max_y])\n",
    "\n",
    "def toggle_selector(event):\n",
    "    print(' Key pressed.')\n",
    "    if event.key in ['Q', 'q'] and toggle_selector.RS.active:\n",
    "        print(' RectangleSelector deactivated.')\n",
    "        toggle_selector.RS.set_active(False)\n",
    "    if event.key in ['A', 'a'] and not toggle_selector.RS.active:\n",
    "        print(' RectangleSelector activated.')\n",
    "        toggle_selector.RS.set_active(True)\n",
    "        \n",
    "# drawtype is 'box' or 'line' or 'none'\n",
    "toggle_selector.RS = RectangleSelector(mapax, line_select_callback,\n",
    "                                       drawtype='box', useblit=True,\n",
    "                                       button=[1, 3],  # don't use middle button\n",
    "                                       minspanx=500, minspany=500,\n",
    "                                       spancoords='data',\n",
    "                                       interactive=True)\n",
    "# plt.connect('key_press_event', toggle_selector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb545bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot last fetched time series with different symbols/colors for each mission\n",
    "sat = np.array([x[0] for x in ins3xr['satellite_img1'].values])\n",
    "dt = ins3xr['date_dt'].values \n",
    "dt = dt.astype(float)*1.15741e-14;\n",
    "max_dt = 90;\n",
    "\n",
    "sats = np.unique(sat)\n",
    "sat_plotsym_dict = {\n",
    "                    '1':'r+',\n",
    "                    '2':'b+',\n",
    "                    '8':'g+',\n",
    "}\n",
    "\n",
    "sat_label_dict = {\n",
    "                    '1':'Sentinel 1',\n",
    "                    '2':'Sentinel 2',\n",
    "                    '8':'Landsat 8',\n",
    "}\n",
    "\n",
    "pltfig2,plotax2 = plt.subplots(1,1,figsize=(9,6))\n",
    "plotax2.set_xlabel('date')\n",
    "plotax2.set_ylabel('speed (m/yr)')\n",
    "plotax2.set_title('ice flow speed pulled directly from S3')\n",
    "\n",
    "for satellite in sats[::-1]:\n",
    "    if any(sat==satellite):\n",
    "        ins3xr.mid_date.values[sat==satellite]\n",
    "        plotax2.plot(ins3xr.mid_date.values[sat==satellite],point_v[sat==satellite], sat_plotsym_dict[satellite], label=sat_label_dict[satellite])\n",
    "\n",
    "plotax2.legend(title='Satellite')\n",
    "pltfig2.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ed9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
