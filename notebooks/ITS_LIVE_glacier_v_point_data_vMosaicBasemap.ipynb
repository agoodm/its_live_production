{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7123f4df-fbc5-4d11-ac57-15b19280deb5",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1><center>\n",
    "        <img src=\"https://its-live-data.s3.amazonaws.com/documentation/ITS_LIVE_logo.png\" width=\"500\"/>\n",
    "        </center></h1>\n",
    "    <h1><center>\n",
    "        glacier velocity point data access<br>\n",
    "        using ITS_LIVE velocity basemap<br>\n",
    "        </center></h1>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Author: Mark Fahnestock, Geophysical Institute, University of Alaska Fairbanks\n",
    "Date: October 28, 202\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c903c8c-0f30-4d5d-ae94-760fc55351b1",
   "metadata": {},
   "source": [
    "# Intro\n",
    "This notebook allows you to select a locaiton from high-resolution imagery, fetch all available ITS_LIVE glacier velocities for that location, and plot the results. These steps can be repeated to plot multiple locations on a single figure. \n",
    "\n",
    "Underling data is stored on AWS S3 as Zarr datacubes and is accessed without an intermediate server. Glacier velocities are derived from all available Landsat 8, Sentinel-1A/B, Sentinel-2A/B imagery.\n",
    "\n",
    "Please refer to the <a href=\"https://its-live.jpl.nasa.gov/\">project website</a> for further product infomation and for appraopriate data citation.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16515a84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting up a local environment\n",
    "\n",
    "at the terminal:\n",
    ">conda create --name pg5 -c conda-forge h5netcdf fiona imagemagick shapely jupyter netcdf4 psutil h5py zarr matplotlib gdal  xarray  boto3 pyproj ipympl s3fs\n",
    "\n",
    "activate newly created environment:\n",
    "> conda activate pg5\n",
    "\n",
    "start jupyter in browser\n",
    "> jupyter notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b732aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first bunch of imports to read and plot timeseries from datacubes in S3 using xarry->zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "# import s3fs as s3\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap # to set up custom ITS_LIVE colormap\n",
    "import time\n",
    "\n",
    "#second bunch to identify datacubes from geojson catalog and picked point\n",
    "import json\n",
    "import shapely\n",
    "import fiona\n",
    "import pyproj\n",
    "from shapely import geometry\n",
    "\n",
    "# gdal for geospatial image io\n",
    "# recent conda installs have gdal in osgeo - just import gdal if this fails (could catch this if a problem)\n",
    "try:\n",
    "    import gdal, osr\n",
    "except:\n",
    "    from osgeo import gdal, osr\n",
    "\n",
    "# set variable\n",
    "global s3path2cube_previous\n",
    "s3path2cube_previous = None\n",
    "\n",
    "# use widget interface in this notebook for interactive pyplot plots\n",
    "# %matplotlib notebook\n",
    "%matplotlib widget\n",
    "\n",
    "import ipywidgets as wdg\n",
    "# use ipywidgets for output text to track progress of download call\n",
    "# output widget is created here, but not displayed until the interactive plot code cell so it stays with plots\n",
    "outwdgt = wdg.Output(layout={'border': '1px solid blue'})\n",
    "\n",
    "# notebook is set up to use regional speed mosaics as basemaps - chose your region here:\n",
    "region = 'GRE'\n",
    "region_dict = {\n",
    "    # HMA is missing - mosaic srs does not return needed EPSG code here, needs to be updated or hard-wired to work\n",
    "#     \"speed_mosaic_URL_base\":'/vsicurl/http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_mosaic/landsat/v00.0/static/cog/',\n",
    "#     \"speed_mosaic_URL_base\":'/vsicurl/https://its-live-data.s3.amazonaws.com/velocity_mosaic/landsat/v00.0/static/cog/',\n",
    "    \"speed_mosaic_URL_base\":'/vsis3/its-live-data/velocity_mosaic/landsat/v00.0/static/cog/',\n",
    "    \"ANT\":{\"pltvmax\":4000, \"speed_mosaic_tif\":'ANT_G0240_0000_v_10_percent_overview.tif'},\n",
    "    \"GRE\":{\"pltvmax\":4000, \"speed_mosaic_tif\":'GRE_G0120_0000_v_10_percent_overview.tif'},\n",
    "    \"ALA\":{\"pltvmax\":625, \"speed_mosaic_tif\":'ALA_G0120_0000_v_10_percent_overview.tif'},\n",
    "    \"SRA\":{\"pltvmax\":625, \"speed_mosaic_tif\":'SRA_G0120_0000_v_25_percent_overview.tif'},\n",
    "    \"CAN\":{\"pltvmax\":625, \"speed_mosaic_tif\":'CAN_G0120_0000_v_10_percent_overview.tif'},\n",
    "    \"PAT\":{\"pltvmax\":625, \"speed_mosaic_tif\":'PAT_G0120_0000_v_25_percent_overview.tif'},\n",
    "}\n",
    "\n",
    "speed_mosaic_URL = region_dict[\"speed_mosaic_URL_base\"] + region_dict[region]['speed_mosaic_tif']\n",
    "# pltvmax is the top end of the color scale used in the map figure\n",
    "speed_mosaic_pltvmax = region_dict[region]['pltvmax']\n",
    "\n",
    "# open image with GDAL and get extents, projection\n",
    "# first set gdal (and via ogr -> fiona(s3://...)) to access public bucket anonomously\n",
    "gdal.SetConfigOption('AWS_NO_SIGN_REQUEST', 'YES')\n",
    "#inmap_gd is gdal geospatial image object\n",
    "inmap_gd=gdal.Open(speed_mosaic_URL)\n",
    "\n",
    "# load velocity mosaic as numpy array to use for basemap\n",
    "vmap=inmap_gd.ReadAsArray()\n",
    "\n",
    "# Nan the nodata pixels so they display as empty\n",
    "inmap_nodata_value = inmap_gd.GetRasterBand(1).GetNoDataValue()\n",
    "vmap[vmap==inmap_nodata_value] = np.nan\n",
    "\n",
    "#get extents of basemap\n",
    "gt = inmap_gd.GetGeoTransform()\n",
    "inmap_min_x = gt[0]\n",
    "inmap_max_x = gt[0] + inmap_gd.RasterXSize * gt[1]\n",
    "inmap_min_y = gt[3] + gt[5]*inmap_gd.RasterYSize\n",
    "inmap_max_y = gt[3]\n",
    "\n",
    "# get pixel size in meters and number of pixels\n",
    "inmap_pix_x_m = gt[1]\n",
    "inmap_pix_y_m = gt[5]\n",
    "inmap_num_pix_x = inmap_gd.RasterXSize\n",
    "inmap_num_pix_y = inmap_gd.RasterYSize\n",
    "\n",
    "# get the basemap projection, find EPSG code to use for reprojecting chosen point locations\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(inmap_gd.GetProjection())\n",
    "map_epsg = srs.GetAuthorityCode('PROJCS')\n",
    "\n",
    "print(f'working with basemap from region {region} - basemap projection EPSG: {map_epsg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce8d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ITS_LIVE default_vel and low_vel color maps\n",
    "# default (- string version below exported from QGIS, 0-4000 m/yr in QGIS files, normalized below to 0-1 for matplotlib)\n",
    "intext_ITSLIVE_QGIS_default = \\\n",
    "\"\"\"0,255,255,255,255,0\n",
    "10,166,238,255,255,10\n",
    "20,166,238,255,255,20\n",
    "40,97,195,219,255,40\n",
    "60,84,169,254,255,60\n",
    "80,84,130,254,255,80\n",
    "100,84,85,254,255,100\n",
    "120,50,119,220,255,120\n",
    "140,16,153,186,255,140\n",
    "160,16,186,153,255,160\n",
    "180,50,220,119,255,180\n",
    "200,84,254,85,255,200\n",
    "220,118,221,51,255,220\n",
    "240,153,186,16,255,240\n",
    "260,187,152,17,255,260\n",
    "280,221,118,51,255,280\n",
    "300,255,85,85,255,300\n",
    "350,255,25,85,255,350\n",
    "450,213,1,72,255,450\n",
    "600,158,1,66,255,600\n",
    "800,140,0,51,255,800\n",
    "1000,122,0,166,255,1000\n",
    "1200,140,0,191,255,1200\n",
    "1400,159,0,217,255,1400\n",
    "2000,213,0,255,255,2000\n",
    "4000,255,0,138,255,4000\n",
    "\"\"\"\n",
    "\n",
    "def make_cmap(name,intext):\n",
    "    lines=intext.split()\n",
    "    # grab max speed value to normalize from 0-1\n",
    "    maxspeedval = float(lines[-1].split(',')[0])\n",
    "\n",
    "    qgis_tuples = []\n",
    "    for line in lines:\n",
    "        x = float(line.split(',')[0])/maxspeedval\n",
    "        r,g,b,a = [float(x)/255.0 for x in line.split(',')[1:-1]]\n",
    "        qgis_tuples.append((x,r,g,b,a))\n",
    "\n",
    "    cdict = { 'red':[], 'green':[], 'blue':[], 'alpha':[] }\n",
    "\n",
    "    for x,r,g,b,a in qgis_tuples:\n",
    "            cdict['red'].append((x,r,r))\n",
    "            cdict['green'].append((x,g,g))\n",
    "            cdict['blue'].append((x,b,b))\n",
    "            cdict['alpha'].append((x,a,a))\n",
    "\n",
    "    vel_colormap = LinearSegmentedColormap(name,cdict)\n",
    "    vel_colormap.set_bad((0.25,0.25,0.25,0.25))\n",
    "    return(vel_colormap)\n",
    "\n",
    "\n",
    "itslive_default_cmap = make_cmap('itslive_default',intext_ITSLIVE_QGIS_default)\n",
    "\n",
    "# result created above can be called with cmap=itslive_default_cmap in plt.imshow, etc.\n",
    "\n",
    "# to display colormap in notebook uncomment next line\n",
    "itslive_default_cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2711b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class s3path2cubeException(Exception):\n",
    "    pass\n",
    "\n",
    "def get_s3path2cube(inpointxy,point_epsg_str):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    if point_epsg_str != '4326':\n",
    "        # point not in lon,lat, set up tranformation and convert it to lon,lat (epsg:4326)\n",
    "        inPROJtoLL = pyproj.Transformer.from_proj(f'epsg:{point_epsg_str}','epsg:4326',always_xy=True)\n",
    "        pointll = inPROJtoLL.transform(*inpointxy)\n",
    "    else:\n",
    "        # point already lon,lat\n",
    "        pointll = inpointxy\n",
    "    \n",
    "    # create Shapely point object for inclusion test\n",
    "    point = geometry.Point(*pointll) # point.coords.xy\n",
    "    \n",
    "    # find datacube outline that contains this point in geojson index file\n",
    "    cubef = None\n",
    "    \n",
    "#     s3/its-live-data.jpl.nasa.gov/datacubes/v01/datacubes_100km_v01.json\n",
    "        \n",
    "    with fiona.open('s3://its-live-data/test_datacubes/v02/datacubes_catalog.json','r') as infio:\n",
    "#    with fiona.open('s3://its-live-data.jpl.nasa.gov/datacubes/v01/datacubes_100km_v01.json','r') as infio:\n",
    "        for f in infio:\n",
    "            polygeom = geometry.shape(f['geometry'])\n",
    "            if polygeom.contains(point):\n",
    "                cubef = f\n",
    "                \n",
    "    if cubef:\n",
    "        print(f'found datacube - elapsed time: {(time.time()-start):10.2f}',flush=True)\n",
    "        \n",
    "        if point_epsg_str == cubef['properties']['data_epsg']:\n",
    "            point_cube_cr = inpointxy\n",
    "        else:\n",
    "            inPROJtoTilePROJ = pyproj.Transformer.from_proj(f'epsg:{point_epsg_str}',cubef['properties']['data_epsg'],always_xy=True)\n",
    "            point_cube_cr = inPROJtoTilePROJ.transform(*inpointxy)\n",
    "\n",
    "        # now test if point is in xy box for cube (should be most of time, could fail because of boundary curvature - 4326 box defined by lon,lat corners, but point chosen in basemap projection)                        \n",
    "        point_cube_cr_shapely = geometry.Point(*point_cube_cr)\n",
    "        polygeomxy = geometry.shape(cubef['properties']['geometry_epsg'])\n",
    "        if not polygeomxy.contains(point_cube_cr_shapely):\n",
    "            raise s3path2cubeException(f\"point is in lat,lon box but not {cubef['properties']['data_epsg']} box!!!!!!!\")\n",
    "            \n",
    "        # for zarr store modify URL for use in boto open - change http: to s3: and lose s3.amazonaws.com\n",
    "        s3path2cube = cubef['properties']['zarr_url'].replace('http:','s3:').replace('.s3.amazonaws.com','')\n",
    "        \n",
    "        return (s3path2cube, point_cube_cr)\n",
    "    else:\n",
    "        raise s3path2cubeException(f'no datacube found for point {pointll}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decorator captures function output in widget\n",
    "@outwdgt.capture(clear_output=True,wait=True)\n",
    "def plotfig(pointxy,nax,map_epsg):\n",
    "    global ins3xr\n",
    "    global point_v \n",
    "    global s3path2cube_previous # hopefully these are available in the global context after a call...\n",
    "    \n",
    "    # pointxy is [x,y] coordinate in mapfig projection (map_epsg below), nax is plot axis for time series plot\n",
    "    start = time.time()\n",
    "    print(f'finding timeseries for point x={pointxy[0]:10.2f} y={pointxy[1]:10.2f} color {colors[color_index]} symbol {symbols[color_index]}',flush=True)\n",
    "\n",
    "    s3path2cube, point_cube_cr = get_s3path2cube(pointxy,map_epsg)\n",
    "    \n",
    "    # only map cube if it's differnet from the last - this could be updated to retain mappings for all unique cubes to avoid multiple reads\n",
    "    if s3path2cube != s3path2cube_previous:\n",
    "        ins3xr = xr.open_dataset(s3path2cube, engine=\"zarr\", storage_options={'anon':True})\n",
    "        s3path2cube_previous = s3path2cube\n",
    "    else:\n",
    "        print(f'data cube previously mapped')\n",
    "    \n",
    "    point_v = ins3xr[\"v\"].sel(x=point_cube_cr[0],y=point_cube_cr[1],method=\"nearest\")\n",
    "    point_v.load()\n",
    "  \n",
    "    dt = ins3xr['date_dt'].values \n",
    "    dt = dt.astype(float)*1.15741e-14;\n",
    "    max_dt = 90; # set the maximum image-pair time seperation (dt) that will be plotted\n",
    "    \n",
    "    nax.plot(ins3xr.mid_date[dt < max_dt],point_v[dt < max_dt], colors[color_index] + symbols[color_index])\n",
    "    total_time = time.time()-start\n",
    "\n",
    "    print(f'elapsed time: {total_time:10.2f} - {len(point_v)/total_time:6.1f} points per second',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e2075",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# from first answer here (how to avoid recording clicks from fig zoom - only a click if no drag) \n",
    "# https://stackoverflow.com/questions/48446351/distinguish-button-press-event-from-drag-and-zoom-clicks-in-matplotlib\n",
    "class Click():\n",
    "    def __init__(self, ax, func, button=1):\n",
    "        self.ax=ax\n",
    "        self.func=func\n",
    "        self.button=button\n",
    "        self.press=False\n",
    "        self.move = False\n",
    "        self.c1=self.ax.figure.canvas.mpl_connect('button_press_event', self.onpress)\n",
    "        self.c2=self.ax.figure.canvas.mpl_connect('button_release_event', self.onrelease)\n",
    "        self.c3=self.ax.figure.canvas.mpl_connect('motion_notify_event', self.onmove)\n",
    "\n",
    "    def onclick(self,event):\n",
    "        if event.inaxes == self.ax:\n",
    "            if event.button == self.button:\n",
    "                self.func(event, self.ax)\n",
    "    def onpress(self,event):\n",
    "        self.press=True\n",
    "    def onmove(self,event):\n",
    "        if self.press:\n",
    "            self.move=True\n",
    "    def onrelease(self,event):\n",
    "        if self.press and not self.move:\n",
    "            self.onclick(event)\n",
    "        self.press=False; self.move=False\n",
    "        \n",
    "pointxy = [np.nan, np.nan] # define here just to see if it is really set in the callback\n",
    "\n",
    "# set up color/symbol sequence for plots - will fail after 18 points...\n",
    "colors = 3*\"bgrmky\"\n",
    "symbols =  \"++++++xxxxxxvvvvvv\"\n",
    "color_index = -1\n",
    "\n",
    "\n",
    "# Define a callback function that will update the map plot and call plotfig to read point data and plot it\n",
    "def onclick(event, ax):\n",
    "    global pointxy    # ensures the pointxy from the scope above is assigned the value when changed\n",
    "    global color_index\n",
    "    ptx = event.xdata\n",
    "    pty = event.ydata\n",
    "\n",
    "    color_index += 1\n",
    "    \n",
    "    # keep map axis from rescaling on point plot\n",
    "    ax.autoscale(False)\n",
    "    # plot marker on map at clicked location\n",
    "    ax.plot(ptx,pty, colors[color_index] + symbols[color_index], mew=4, ms=10)\n",
    "    \n",
    "    pointxy = [ptx,pty]\n",
    "    \n",
    "    # get time series at point and add it to the time series plot\n",
    "    plotfig(pointxy,plotax,map_epsg)\n",
    "\n",
    "\n",
    "    \n",
    "mapfig,mapax = plt.subplots(1,1,figsize=(9,9))\n",
    "\n",
    "colormappable = mapax.imshow(vmap,vmin=0,vmax=speed_mosaic_pltvmax,cmap=itslive_default_cmap,extent=[inmap_min_x,inmap_max_x,inmap_min_y,inmap_max_y],alpha=0.7)\n",
    "mapfig.tight_layout()\n",
    "mapax.set_title(region)\n",
    "mapfig.colorbar(colormappable)\n",
    "\n",
    "# from IPython.display import display\n",
    "display(outwdgt)\n",
    "\n",
    "pltfig,plotax = plt.subplots(1,1,figsize=(9,6))\n",
    "plotax.set_xlabel('date')\n",
    "plotax.set_ylabel('speed (m/yr)')\n",
    "plotax.set_title('ITS_LIVE glacier speed')\n",
    "\n",
    "pltfig.tight_layout()\n",
    "\n",
    "click = Click(mapax, onclick, button=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79415c46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sat = np.array([x[0] for x in ins3xr['satellite_img1'].values])\n",
    "dt = ins3xr['date_dt'].values \n",
    "dt = dt.astype(float)*1.15741e-14;\n",
    "max_dt = 590;\n",
    "sats = np.unique(sat)\n",
    "sat_plotsym_dict = {\n",
    "                    '1':'r+',\n",
    "                    '2':'b+',\n",
    "                    '8':'g+',\n",
    "}\n",
    "\n",
    "sat_label_dict = {\n",
    "                    '1':'Sentinel 1',\n",
    "                    '2':'Sentinel 2',\n",
    "                    '8':'Landsat 8',\n",
    "}\n",
    "\n",
    "pltfig2,plotax2 = plt.subplots(1,1,figsize=(9,6))\n",
    "plotax2.set_xlabel('date')\n",
    "plotax2.set_ylabel('speed (m/yr)')\n",
    "plotax2.set_title('ITS_LIVE glacier speed')\n",
    "\n",
    "for satellite in sats[::-1]:\n",
    "    plotax2.plot(ins3xr.mid_date.values[(sat==satellite) & (dt < max_dt)],point_v.values[(sat==satellite) & (dt < max_dt)], sat_plotsym_dict[satellite], label=sat_label_dict[satellite])\n",
    "\n",
    "plotax2.legend(title='Satellite')\n",
    "pltfig2.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1025d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
